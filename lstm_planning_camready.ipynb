{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_planning2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baV6JoFCzqmz"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kliNwIyOblaJ"
      },
      "source": [
        "# Allows you to make changes in the library files and include them in the \n",
        "# notebook without restarting the kernel\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msUUoc73sjeh"
      },
      "source": [
        "# Python Library Imports\n",
        "import numpy as np\n",
        "import random\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib.animation as animation\n",
        "import math\n",
        "import queue\n",
        "import time \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils\n",
        "from torch.autograd import Variable\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.integrate import ode, odeint\n",
        "%matplotlib inline\n",
        "\n",
        "### REPO IMPORTS ###\n",
        "import astar_tree_search\n",
        "import baseline_planners\n",
        "import dataset_generation\n",
        "import deadbeat_net\n",
        "import hopper\n",
        "import models\n",
        "from models import StepSequenceModelConv\n",
        "import rnn_planners\n",
        "import terrain_utils\n",
        "import test_utils\n",
        "import training_utils\n",
        "import utils\n",
        "import evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkXPTjNu0QRl"
      },
      "source": [
        "Defining Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFQUTS6x0Prp",
        "outputId": "b9002e6f-43a5-4e5e-e45d-655911292e9b"
      },
      "source": [
        "glob_dir = \"./\"\n",
        "dataset_dir = glob_dir + \"datasets/\"\n",
        "model_dir = glob_dir + \"models/\"\n",
        "anim_dir = glob_dir + \"animations/\"\n",
        "pics_dir = glob_dir + \"images/\"\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"using GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"warning: using cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcq3gV7hzkPi"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFijo43hI6pp"
      },
      "source": [
        "### Multithreaded dataset generation with Angle-space planner\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nze8T--A0Jxq"
      },
      "source": [
        "def cost_function(x_flight, neighbors, goal, p):\n",
        "  x_pos = x_flight[0]\n",
        "  x_vel = x_flight[2]\n",
        "  spread = 0\n",
        "  # calculate spread of neighbors\n",
        "  for n in range(len(neighbors)):\n",
        "    spread += np.abs(neighbors[n][0] - x_pos)/len(neighbors)\n",
        "   \n",
        "  return 0.5 * np.abs(x_pos - goal[0]) + 0.5 * np.abs(x_vel - goal[1]) + 1 * spread\n",
        "\n",
        "robot = hopper.Hopper(hopper.Constants())\n",
        "max_seq_length = 15\n",
        "\n",
        "def gen_args(seed):\n",
        "  return (robot, 24, 8, 8, 8, 0.6, cost_function, True, 0.1, False, seed)\n",
        "\n",
        "num_proc = 15\n",
        "all_args = [gen_args(np.random.randint(1, 100)) for i in range(num_proc)]\n",
        "p = mp.Pool(processes = num_proc)\n",
        "return_val_array = p.starmap(dataset_generation.generateRandomSequences, all_args)\n",
        "all_initial_states = []\n",
        "all_sequences = []\n",
        "\n",
        "for r in return_val_array:\n",
        "  initial_states = r[0]\n",
        "  sequences = r[1]\n",
        "  for i in range(len(initial_states)):\n",
        "    if max_seq_length > 0 and len(sequences[i]) < max_seq_length:\n",
        "      all_initial_states.append(initial_states[i])\n",
        "      all_sequences.append(sequences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPloM4tqmXTu"
      },
      "source": [
        "print(len(all_sequences))\n",
        "lens = [0 for i in range(50)]\n",
        "for i in range(len(all_sequences)):\n",
        "  lens[len(all_sequences[i])] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7KBjHqs0dK_"
      },
      "source": [
        "suffix = \"360_120_spread3.npy\"\n",
        "suffix_oh = \"360_120_spread3_oh.npy\"\n",
        "\n",
        "np.save(dataset_dir + \"rnn_inits_\" + suffix, all_initial_states)\n",
        "np.save(dataset_dir + \"rnn_seqs_\" + suffix, all_sequences)\n",
        "sequences_oh = utils.oneHotEncodeSequences(all_sequences)\n",
        "np.save(dataset_dir + \"rnn_seqs_\" + suffix_oh, sequences_oh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URZJtzSDzkHN"
      },
      "source": [
        "# Training Convolutional-Input Recurrent Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYaOEisXX0kf"
      },
      "source": [
        "Loading & Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pALa2j8-ZCq"
      },
      "source": [
        "suffix = \"360_120_spread3.npy\"\n",
        "suffix_oh = \"360_120_spread3_oh.npy\"\n",
        "\n",
        "init_states = np.load(dataset_dir + \"rnn_inits_\" + suffix, allow_pickle = True)\n",
        "sequences_oh = np.load(dataset_dir + \"rnn_seqs_\" + suffix_oh, allow_pickle = True)\n",
        "sequences = np.load(dataset_dir + \"rnn_seqs_\" + suffix, allow_pickle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wvDLfA-YNxi"
      },
      "source": [
        "init_apexes, sequences_and_terrains = utils.concatenateTerrainsAndOHSteps(init_states, sequences_oh)\n",
        "all_batches = utils.createDataBatches(sequences_and_terrains, init_apexes, batch_size = 64, train_pct = 0.9)\n",
        "train_seq_batches = all_batches[0]\n",
        "train_iv_batches = all_batches[1]\n",
        "test_seq_batches = all_batches[2]\n",
        "test_iv_batches = all_batches[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Hno0-ZZLoA"
      },
      "source": [
        "Training Convolutional-Input LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeGSGw4uZUsC"
      },
      "source": [
        " # Fixed parameters based on the initial state/terrain sizes \n",
        "init_data_dim = 3\n",
        "input_size = 110\n",
        "output_size = 110\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_dim = 110\n",
        "n_layers = 2\n",
        "use_lstm = True\n",
        "ksize = 7\n",
        "\n",
        "model = StepSequenceModelConv(init_dim = init_data_dim,\n",
        "                              input_size = input_size,\n",
        "                              output_size = output_size,\n",
        "                              hidden_dim = hidden_dim,\n",
        "                              n_layers = n_layers,\n",
        "                              use_lstm = use_lstm,\n",
        "                              ksize = ksize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv9px7tqZcP0"
      },
      "source": [
        "n_epochs = 15\n",
        "lr = 1e-3\n",
        "model = training_utils.trainConvRNN(model,\n",
        "                                    n_epochs,\n",
        "                                    lr,\n",
        "                                    train_seq_batches,\n",
        "                                    train_iv_batches,\n",
        "                                    device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpzPJ5IwZgzd"
      },
      "source": [
        " if use_lstm:\n",
        "  model_name = \"ConvLSTM_trained_\"\n",
        "else:\n",
        "  model_name = \"ConvRNN_trained_\"\n",
        "model_name += str(n_layers) + \"x\" + str(hidden_dim) + \"_\" + suffix[:-4]\n",
        "torch.save(model, model_dir + model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_CvrAqya7D-"
      },
      "source": [
        "Test loss of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zukdsRK-a-q2"
      },
      "source": [
        "model = model.eval()\n",
        "training_utils.convRNNValidation(model, test_seq_batches, test_iv_batches, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO0k4zWIWrS4"
      },
      "source": [
        "# Loading Pretrained Models and Controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdNWksdlWtEK"
      },
      "source": [
        "db_net = deadbeat_net.DeadbeatNet()\n",
        "db_net.load_state_dict(torch.load(glob_dir + \"deadbeat_net_state_1104\", map_location = device))\n",
        "db_net = db_net.to(device)\n",
        "\n",
        "step_controller = deadbeat_net.DeadbeatStepController(hopper.constants, db_net, ks = 0.0, device = device)\n",
        "model = torch.load(model_dir + \"ConvLSTM_trained_2x110_360_120_spreadhalf\", map_location = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcKHcMUWuy0"
      },
      "source": [
        "# Generate/Load Test Suites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFaIZ5jxjIki"
      },
      "source": [
        "Generate test matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oglYpJm7WyJM"
      },
      "source": [
        "num_apexes = 5\n",
        "ditch_profile = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]\n",
        "step_profile = [2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n",
        "\n",
        "ditch_test_matrix = test_utils.generateTestMatrix(ditch_profile, num_apexes)\n",
        "step_test_matrix = test_utils.generateStepTestMatrix(step_profile, num_apexes)\n",
        "\n",
        "import pickle\n",
        "fname = \"ditch_test_matrix_\" + str(len(ditch_profile)) + str(\"x\") + str(num_apexes)\n",
        "with open(fname, \"wb\") as f:\n",
        "  pickle.dump(ditch_test_matrix, f)\n",
        "\n",
        "fname = \"step_test_matrix_\" + str(len(step_profile)) + str(\"x\") + str(num_apexes) + \"_4\"\n",
        "with open(fname, \"wb\") as f:\n",
        "  pickle.dump(step_test_matrix, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwiGGPyCjNv2"
      },
      "source": [
        "Load Test Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi_9wFDrjYf5"
      },
      "source": [
        "import pickle\n",
        "\n",
        "fname = \"ditch_test_matrix_15x5\"\n",
        "with open(fname, 'rb') as f:\n",
        "  ditch_test_matrix = pickle.load(f)\n",
        "\n",
        "fname = \"step_test_matrix_15x5_4\"\n",
        "with open(fname, 'rb') as f:\n",
        "  step_test_matrix = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IkYesQpXAOK"
      },
      "source": [
        "# Evaluate Planners on Test Suite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIB4SP-9Xd1P"
      },
      "source": [
        "### Receding Horizon A* Planner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZAhgGBLop7X"
      },
      "source": [
        "robot = hopper.Hopper(hopper.Constants())\n",
        "astar_planner = baseline_planners.AStarPlanner(robot, num_samples = 20, fallback_samples = 30,\n",
        "                                               max_speed = 4, cost_matrix = [1, 1, 2])\n",
        "tr = evaluation.testSearchPlannerOnMatrix(robot, astar_planner, step_controller,\n",
        "                                          step_test_matrix, friction = 0.8, time_to_replan = 3, tstep = 0.01)\n",
        "\n",
        "print()\n",
        "tr.printMetrics()\n",
        "readable_failures = {hopper.sim_codes_rev[i]:tr.failure_cases[i] for i in tr.failure_cases.keys()}\n",
        "print(readable_failures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK046Wkd3zat"
      },
      "source": [
        "### Footstep Space A* Planner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAo7tXyU97Sk"
      },
      "source": [
        "# Could use different robot here to evaluate robustness to model perturbations\n",
        "robot = hopper.Hopper(hopper.Constants())\n",
        "foot_astar_planner = baseline_planners.FootSpaceAStarPlanner(robot, horizon = 5, spacing = 0.25,\n",
        "                                                             cost_matrix = [1.0, 0.5, 0.5],\n",
        "                                                             step_controller = step_controller)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKfyL3W31yl"
      },
      "source": [
        "perturbed_controller = deadbeat_net.PerturbedStepController(step_controller, 0.00)\n",
        "tr = evaluation.testSearchPlannerOnMatrix(robot, foot_astar_planner,\n",
        "                                          step_controller, step_test_matrix,\n",
        "                                          friction = 0.8, time_to_replan = 3,\n",
        "                                          tstep = 0.01)\n",
        "print()\n",
        "tr.printMetrics()\n",
        "readable_failures = {hopper.sim_codes_rev[i]:tr.failure_cases[i] for i in tr.failure_cases.keys()}\n",
        "print(readable_failures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5z38bx9v3F"
      },
      "source": [
        "Generate Animations of footstep planner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_h_Tyt99yZw"
      },
      "source": [
        "terrain_idx = 5\n",
        "apex_idx = 0\n",
        "\n",
        "code, body_poses, foot_poses, plans, num_steps_hit, total_odes, _ = evaluation.testPlannerSingle(robot, foot_astar_planner, step_controller,\n",
        "                                                                                              ditch_test_matrix, 2,\n",
        "                                                                                              terrain_idx, apex_idx, friction = 0.8)\n",
        "\n",
        "# Generate the animation from the matrix\n",
        "funcs = ditch_test_matrix.getFunctions()\n",
        "func = funcs[terrain_idx]\n",
        "fig, ax = plt.subplots()\n",
        "terrain_utils.plot_terrain(ax, 0, 8, func)\n",
        "name = anim_dir + \"footstep_planner_\" + str(terrain_idx) + \"_\" + str(apex_idx) + \".mp4\"\n",
        "# utils.animateMovingXAxis(body_poses, foot_poses, anim_name = name, plans = plans, terrain_func = func, nogo = None, fps = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHeRJjmdXpdS"
      },
      "source": [
        "### Receding-Horizon Heuristic Stride Planner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVUMYVffHLS9"
      },
      "source": [
        "h_planner = baseline_planners.HeuristicPlanner(stride = 1.0, buffer = 0.2)\n",
        "robot = hopper.Hopper(hopper.Constants())\n",
        "tr = evaluation.testSearchPlannerOnMatrix(robot, h_planner, step_controller, step_test_matrix,\n",
        "                                          friction = 0.8, time_to_replan = 3, tstep = 0.01)\n",
        "\n",
        "print()\n",
        "tr.printMetrics()\n",
        "readable_failures = {hopper.sim_codes_rev[i]:tr.failure_cases[i] for i in tr.failure_cases.keys()}\n",
        "print(readable_failures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWu5dT3XC0x"
      },
      "source": [
        "### Receding-Horizon RNN Guided A*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75V2TWbWGshu"
      },
      "source": [
        "robot = hopper.Hopper(hopper.Constants())\n",
        "rnn_planner = rnn_planners.ConvRNNPlanner(model, device, min_limit = -3, T = 3)\n",
        "rnn_astar_planner = rnn_planners.RNNAStarPlanner(robot, rnn_planner, step_controller,\n",
        "                                                 num_samples = 3, fallback_samples = 5,\n",
        "                                                 cost_matrix = [1, 0.5, 0.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWXMce0lXCW3"
      },
      "source": [
        "# Wraps the ConvRNNPlanner in a tree search.\n",
        "perturbed_controller = deadbeat_net.PerturbedStepController(step_controller, 0.00)\n",
        "test_results2 = evaluation.testSearchPlannerOnMatrix(robot, rnn_astar_planner,\n",
        "                                                     perturbed_controller, ditch_test_matrix,\n",
        "                                                     friction = 0.8, time_to_replan = 3,\n",
        "                                                     tstep = 0.01)\n",
        "\n",
        "print()\n",
        "test_results2.printMetrics()\n",
        "readable_failures = {hopper.sim_codes_rev[i]:test_results2.failure_cases[i] for i in test_results2.failure_cases.keys()}\n",
        "print(readable_failures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iGTeiKMDHBp"
      },
      "source": [
        "Generating Animations/Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC823xc3DKzD"
      },
      "source": [
        "terrain_idx = 13\n",
        "apex_idx = 0\n",
        "\n",
        "code, body_poses, foot_poses, plans, num_steps_hit, total_odes = evaluation.testPlannerSingle(robot,\n",
        "                                                                                              rnn_astar_planner,\n",
        "                                                                                              step_controller, \n",
        "                                                                                              step_test_matrix2,\n",
        "                                                                                              3,\n",
        "                                                                                              terrain_idx,\n",
        "                                                                                              apex_idx,\n",
        "                                                                                              friction = 0.8)\n",
        "\n",
        "funcs = step_test_matrix2.getFunctions()\n",
        "func = funcs[terrain_idx]\n",
        "name = anim_dir + \"rnn_astar_planner_step2_\" + str(terrain_idx) + \"_\" + str(apex_idx) + \".mp4\"\n",
        "\n",
        "utils.animateMovingXAxis(body_poses, foot_poses, name, plans, nogo=None, terrain_func = func, fps = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7zrOG7SXWy_"
      },
      "source": [
        "###RNN planner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP0gAn_cXaok"
      },
      "source": [
        "rnn_planner = rnn_planners.ConvRNNPlanner(model, device, -3, T = 1)\n",
        "robot = hopper.Hopper(hopper.Constants())\n",
        "perturbed_controller = deadbeat_net.PerturbedStepController(step_controller, 0.00)\n",
        "rnn_test_results = evaluation.testRNNPlannerOnMatrix(robot,\n",
        "                                                     rnn_planner,\n",
        "                                                     perturbed_controller,\n",
        "                                                     step_test_matrix,\n",
        "                                                     time_to_replan = 3,\n",
        "                                                     friction = 0.8,\n",
        "                                                     tstep = 0.01)\n",
        "print()\n",
        "rnn_test_results.printMetrics()\n",
        "readable_failures = {hopper.sim_codes_rev[i]:rnn_test_results.failure_cases[i] for i in rnn_test_results.failure_cases.keys()}\n",
        "print(readable_failures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SItQFWpRFqM_"
      },
      "source": [
        "# Miscellaneous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz2djqGM0yXA"
      },
      "source": [
        "## Qualitatively evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlKvThEiFpxr",
        "outputId": "95085383-997c-4b04-a727-122f8cbdeaa4"
      },
      "source": [
        "idx = 8\n",
        "test_matrix = ditch_test_matrix\n",
        "terrain_array = test_matrix.arrays[idx]\n",
        "terrain_func = test_matrix.getFunctions()[idx]\n",
        "prev_steps = [[0.0]]\n",
        "tnf = lambda x: np.pi/2\n",
        "initial_apex = [0, 1.0, 0]\n",
        "outs, softmaxes, hiddens = models.evaluateConvModel(model, 2, initial_apex, prev_steps, terrain_array, device, T = 1)\n",
        "print(outs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20000004768371582, 0.7000000476837158]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z402BwMF2lF"
      },
      "source": [
        "softmax_np = softmaxes[-1].cpu().detach().numpy()[0][0]\n",
        "utils.plotProbabilitiesOverTerrain(outs,\n",
        "                                  initial_apex,\n",
        "                                  softmax_np,\n",
        "                                  terrain_func,\n",
        "                                  None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjykEFOVK13_"
      },
      "source": [
        "## Generating data for the deadbeat controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqjdlwSINLA8"
      },
      "source": [
        "def generateStepData(num_vels, num_angles, min_vi, max_vi, min_y, max_y, friction = 1.5):\n",
        "  input_velocities = np.linspace(min_vi, max_vi, num_vels)\n",
        "  input_ys = np.linspace(min_y, max_y, 50)\n",
        "  vels, ys = np.meshgrid(input_velocities, input_ys)\n",
        "  vels = np.ravel(vels)\n",
        "  ys = np.ravel(ys)\n",
        "  velocities = []\n",
        "  angles = []\n",
        "  min_limit = np.pi/2 - np.arctan(friction)\n",
        "  max_limit = np.pi/2 + np.arctan(friction)\n",
        "  terrain_func = lambda x: 0\n",
        "  terrain_normal_func = lambda x: np.pi/2\n",
        "  for i in range(len(vels)):\n",
        "    if i%100 == 0:\n",
        "      print(i, \"/\", len(vels))\n",
        "    vel = vels[i]\n",
        "    y = ys[i]\n",
        "    input_angles = np.linspace(min_limit, max_limit, num_angles)\n",
        "    for inp in input_angles:\n",
        "      x0_apex = [0, y, vel, 0, 0, inp]\n",
        "      apex1, apex2, last_flight = hopper.getNextState2(x0_apex, inp, lambda x: 0, lambda x: np.pi/2, friction)\n",
        "      if apex1 is not None:\n",
        "        velocities.append([vel, y, last_flight[0]])\n",
        "        angles.append(inp)\n",
        "  return np.array(velocities), np.array(angles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Jv2RtAVjcY"
      },
      "source": [
        "# dir = \"/content/drive/My Drive/Research/legged_planning_learning/\"\n",
        "data_fname = dataset_dir + \"deadbeat_datapoints.npy\"\n",
        "lab_fname = dataset_dir + \"deadbeat_labels.npy\"\n",
        "\n",
        "inputs, labels = generateStepData(100, 100, -3, 3, 0.6, 1.5, friction = 0.8)\n",
        "np.save(glob_dir + data_fname, inputs)\n",
        "np.save(glob_dir + lab_fname, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c6Xr1c9IfHj"
      },
      "source": [
        "## Training the controller net\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w3_uzSfIesB"
      },
      "source": [
        "# dir = \"/content/drive/My Drive/Research/legged_planning_learning/\"\n",
        "data_fname = \"deadbeat_datapoints.npy\"\n",
        "lab_fname = \"deadbeat_labels.npy\"\n",
        "\n",
        "deadbeat_dset = np.load(glob_dir + data_fname)\n",
        "deadbeat_labels = np.load(glob_dir + lab_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NV5lw15tyCv"
      },
      "source": [
        "train_pct = 0.9\n",
        "train_length = int(deadbeat_dset.shape[0] * train_pct)\n",
        "test_length = deadbeat_dset.shape[0] - train_length\n",
        "\n",
        "full_torch_dset = torch.utils.data.TensorDataset(torch.from_numpy(deadbeat_dset).float(),\n",
        "                                     torch.from_numpy(deadbeat_labels).float())\n",
        "trainset, testset = torch.utils.data.random_split(full_torch_dset, [train_length, test_length])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                              shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPxrXeiX0sBT"
      },
      "source": [
        "db_net = deadbeat_net.DeadbeatNet()\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"using GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"warning: using cpu\")\n",
        "db_net = db_net.to(device)\n",
        "\n",
        "lr = 1e-3\n",
        "n_epochs = 100\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(db_net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqVJyAN2-7hN"
      },
      "source": [
        "# training loop for RNN\n",
        "for epoch in range(1, n_epochs):\n",
        "  losses = []\n",
        "  # iterating over batches\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    output = torch.squeeze(db_net(inputs))\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    losses.append(loss.item())\n",
        "    if i % 100 == 0:\n",
        "      print(\"Epoch\", epoch, \"Batch \", i, \"Loss:\", loss.item())\n",
        "  \n",
        "  print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "  print(\"Loss: {:.4f}\".format(np.mean(losses)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOEtyQU86eef"
      },
      "source": [
        "# testing loop\n",
        "db_net = db_net.eval()\n",
        "test_loss = 0\n",
        "num_batches = 0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  output = torch.squeeze(db_net(inputs))\n",
        "  loss = criterion(output, labels)\n",
        "  num_batches += 1\n",
        "  test_loss += loss.item()\n",
        "\n",
        "avg_test_loss = test_loss/num_batches\n",
        "print(\"test loss = \", avg_test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5X00hhO7voJ"
      },
      "source": [
        "torch.save(db_net.state_dict(), glob_dir + \"deadbeat_net_state_1104\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}